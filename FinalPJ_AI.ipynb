{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11Sz9d8Jo5dgjKCEGb_Bnlk_ks_PizIYI",
      "authorship_tag": "ABX9TyMjTfYtgihM0Nch/aZipwaP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thuan20146215/AI/blob/main/FinalPJ_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer"
      ],
      "metadata": {
        "id": "oyVoyusmhHqd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('train.csv')\n",
        "df=df.dropna()###Drop Nan Values\n",
        "X=df.drop('label',axis=1)\n",
        "#X=df['title']\n",
        "y=df['label']"
      ],
      "metadata": {
        "id": "fmpW4PLNhRWQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfGT7zV3ocgu",
        "outputId": "a4b5c12c-49df-4899-f65c-9eedb1139f5c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     1\n",
              "1     0\n",
              "2     1\n",
              "3     1\n",
              "4     1\n",
              "5     0\n",
              "7     0\n",
              "9     0\n",
              "10    0\n",
              "11    0\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Vocabulary size\n",
        "voc_size=5000"
      ],
      "metadata": {
        "id": "p62q0leJl60Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages=X.copy()\n",
        "\n",
        "messages.reset_index(inplace=True)\n"
      ],
      "metadata": {
        "id": "eyPY_O_Vl70l"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "zxvQqfPCmTuF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXZ3cfXHmUmM",
        "outputId": "c501abcc-c2fe-4624-f6e6-fd0b54eb7df5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Dataset Preprocessing\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "corpus = []\n",
        "for i in range(0, len(messages)):\n",
        "  \n",
        "    review = re.sub('[^a-zA-Z]', ' ', messages['title'][i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)"
      ],
      "metadata": {
        "id": "evF6bpNqmaAv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_repr=[one_hot(words,voc_size)for words in corpus] \n",
        "onehot_repr"
      ],
      "metadata": {
        "id": "4kqevPMLppyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_length=20\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
        "print(embedded_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GilzZrp5qCc1",
        "outputId": "61bac445-aeff-46ac-ed40-aab5f65d7506"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0 ... 4623  870 1998]\n",
            " [   0    0    0 ...  133 2887 2619]\n",
            " [   0    0    0 ... 4189 3200  171]\n",
            " ...\n",
            " [   0    0    0 ... 3340 1450 3052]\n",
            " [   0    0    0 ... 2099  856  772]\n",
            " [   0    0    0 ...   53 3720 3061]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iGnktrqqKKh",
        "outputId": "42e359fd-86b3-4bf7-a51b-ed80da38e01f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 1085,\n",
              "       3937, 2404, 3971, 1265, 4135,  349, 4623,  870, 1998], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "## Creating model\n",
        "embedding_vector_features=40\n",
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "wp2PVy8pqLXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f87ad76-1534-4bd5-95d3-fb040bb5b5ee"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 20, 40)            200000    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 20, 40)            0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               56400     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,601\n",
            "Trainable params: 266,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(embedded_docs),y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_LEg-m-qbXj",
        "outputId": "3525412a-4b17-4aa8-be57-489b8ae8df8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18285, (18285,))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X_final=np.array(embedded_docs)\n",
        "y_final=np.array(y)"
      ],
      "metadata": {
        "id": "dVc-ciEaqbqn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_final.shape,y_final.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlxB43ZJqgv2",
        "outputId": "97bbcf9f-1ac6-4128-eaea-4d458cd48c1c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((18285, 20), (18285,))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "_UiZJAxoqj-v"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Finally Training\n",
        "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100,batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kiy71x77qtZR",
        "outputId": "57b7bfc6-23be-4073-8d68-d3db15d689ce"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 0.3025 - accuracy: 0.8746 - val_loss: 0.2059 - val_accuracy: 0.9112\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 0.1489 - accuracy: 0.9424 - val_loss: 0.2065 - val_accuracy: 0.9127\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.1078 - accuracy: 0.9594 - val_loss: 0.2374 - val_accuracy: 0.9151\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - 9s 46ms/step - loss: 0.0751 - accuracy: 0.9737 - val_loss: 0.2626 - val_accuracy: 0.9065\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 0.0513 - accuracy: 0.9816 - val_loss: 0.3361 - val_accuracy: 0.9107\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.0364 - accuracy: 0.9866 - val_loss: 0.3688 - val_accuracy: 0.9078\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 11s 54ms/step - loss: 0.0257 - accuracy: 0.9914 - val_loss: 0.4123 - val_accuracy: 0.9121\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 9s 46ms/step - loss: 0.0247 - accuracy: 0.9909 - val_loss: 0.4168 - val_accuracy: 0.9092\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.0207 - accuracy: 0.9925 - val_loss: 0.4772 - val_accuracy: 0.9085\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.5182 - val_accuracy: 0.9087\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 9s 45ms/step - loss: 0.0117 - accuracy: 0.9954 - val_loss: 0.5182 - val_accuracy: 0.9054\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.6126 - val_accuracy: 0.9065\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.6553 - val_accuracy: 0.9017\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 11s 54ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.5765 - val_accuracy: 0.9016\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 9s 45ms/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.5521 - val_accuracy: 0.9017\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 0.0071 - accuracy: 0.9973 - val_loss: 0.5921 - val_accuracy: 0.9089\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.6206 - val_accuracy: 0.9059\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 9s 44ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.5822 - val_accuracy: 0.9079\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 11s 54ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 0.6438 - val_accuracy: 0.9105\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 12s 58ms/step - loss: 0.0066 - accuracy: 0.9975 - val_loss: 0.6429 - val_accuracy: 0.9043\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 0.0052 - accuracy: 0.9979 - val_loss: 0.6715 - val_accuracy: 0.9061\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 9s 43ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.7152 - val_accuracy: 0.9032\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.6732 - val_accuracy: 0.9065\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.6501 - val_accuracy: 0.9074\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 9s 44ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.7676 - val_accuracy: 0.9079\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.8147 - val_accuracy: 0.9052\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.6574 - val_accuracy: 0.9048\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.6625 - val_accuracy: 0.9089\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 9s 46ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.7118 - val_accuracy: 0.9074\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 0.7850 - val_accuracy: 0.9014\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.7444 - val_accuracy: 0.9052\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 9s 45ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 0.7193 - val_accuracy: 0.9032\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.7249 - val_accuracy: 0.9058\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.7159 - val_accuracy: 0.9043\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.7519 - val_accuracy: 0.9041\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.7418 - val_accuracy: 0.9043\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.7694 - val_accuracy: 0.9048\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.7788 - val_accuracy: 0.9056\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 9s 45ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.7814 - val_accuracy: 0.9041\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.8214 - val_accuracy: 0.9079\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.7786 - val_accuracy: 0.9094\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.8119 - val_accuracy: 0.9041\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 10s 49ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.7680 - val_accuracy: 0.9085\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.7407 - val_accuracy: 0.9085\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 11s 58ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.8000 - val_accuracy: 0.9045\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.8009 - val_accuracy: 0.8994\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 11s 54ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.8280 - val_accuracy: 0.9052\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.8210 - val_accuracy: 0.9019\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.8912 - val_accuracy: 0.9063\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 9s 45ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.8319 - val_accuracy: 0.9047\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.8590 - val_accuracy: 0.9017\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.9072 - val_accuracy: 0.9028\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.8451 - val_accuracy: 0.9045\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 11s 54ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.8924 - val_accuracy: 0.8983\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.8967 - val_accuracy: 0.9032\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0018 - accuracy: 0.9991 - val_loss: 0.8930 - val_accuracy: 0.9027\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 9s 45ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.7877 - val_accuracy: 0.9067\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 8.3758e-04 - accuracy: 0.9998 - val_loss: 0.8918 - val_accuracy: 0.9052\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 1.0214 - val_accuracy: 0.9032\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.8987 - val_accuracy: 0.9050\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 8.9648e-04 - accuracy: 0.9996 - val_loss: 0.9041 - val_accuracy: 0.9059\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 11s 54ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.9992 - val_accuracy: 0.8979\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.9113 - val_accuracy: 0.9052\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.9789 - val_accuracy: 0.9010\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 1.0083 - val_accuracy: 0.9021\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 12s 58ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.9732 - val_accuracy: 0.9034\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 9s 44ms/step - loss: 9.8238e-04 - accuracy: 0.9995 - val_loss: 1.0365 - val_accuracy: 0.8994\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 1.0652 - val_accuracy: 0.8925\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 0.9147 - val_accuracy: 0.9072\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.8513 - val_accuracy: 0.9079\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 9s 46ms/step - loss: 5.8540e-04 - accuracy: 0.9998 - val_loss: 0.9575 - val_accuracy: 0.9032\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 2.2129e-04 - accuracy: 1.0000 - val_loss: 0.9645 - val_accuracy: 0.9067\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 12s 58ms/step - loss: 8.6175e-04 - accuracy: 0.9996 - val_loss: 0.9892 - val_accuracy: 0.9036\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 9s 45ms/step - loss: 9.1726e-04 - accuracy: 0.9998 - val_loss: 0.9582 - val_accuracy: 0.9072\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 6.1952e-04 - accuracy: 0.9997 - val_loss: 1.0315 - val_accuracy: 0.9045\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 7.6575e-04 - accuracy: 0.9996 - val_loss: 1.0981 - val_accuracy: 0.8979\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.9763 - val_accuracy: 0.9021\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 9.7824e-04 - accuracy: 0.9998 - val_loss: 0.9977 - val_accuracy: 0.9038\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.9490 - val_accuracy: 0.9058\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 12s 58ms/step - loss: 2.1581e-04 - accuracy: 0.9999 - val_loss: 1.0748 - val_accuracy: 0.9063\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 1.0287 - val_accuracy: 0.9007\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 8.6982e-05 - accuracy: 1.0000 - val_loss: 1.0139 - val_accuracy: 0.9063\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.9412 - val_accuracy: 0.9056\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 3.4468e-04 - accuracy: 0.9998 - val_loss: 1.0360 - val_accuracy: 0.9034\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 9s 46ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.9670 - val_accuracy: 0.9010\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 9.2796e-04 - accuracy: 0.9998 - val_loss: 0.9750 - val_accuracy: 0.8994\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 2.3806e-04 - accuracy: 1.0000 - val_loss: 1.0672 - val_accuracy: 0.9034\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 9s 44ms/step - loss: 7.9962e-05 - accuracy: 1.0000 - val_loss: 1.1137 - val_accuracy: 0.9041\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.9672 - val_accuracy: 0.9078\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 1.0741 - val_accuracy: 0.9030\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.9355 - val_accuracy: 0.9074\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 11s 54ms/step - loss: 7.7357e-04 - accuracy: 0.9997 - val_loss: 0.9424 - val_accuracy: 0.9021\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 4.7346e-04 - accuracy: 0.9998 - val_loss: 1.0513 - val_accuracy: 0.9019\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 1.4922e-04 - accuracy: 1.0000 - val_loss: 1.0378 - val_accuracy: 0.9034\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 9s 45ms/step - loss: 6.5220e-05 - accuracy: 1.0000 - val_loss: 1.0363 - val_accuracy: 0.9065\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 7.3756e-04 - accuracy: 0.9998 - val_loss: 1.0098 - val_accuracy: 0.9017\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 7.7937e-04 - accuracy: 0.9997 - val_loss: 0.9524 - val_accuracy: 0.9059\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 9s 45ms/step - loss: 4.3689e-05 - accuracy: 1.0000 - val_loss: 0.9928 - val_accuracy: 0.9074\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 1.5048e-04 - accuracy: 0.9999 - val_loss: 1.0387 - val_accuracy: 0.9045\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 4.0167e-05 - accuracy: 1.0000 - val_loss: 1.0716 - val_accuracy: 0.9032\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5d54081c60>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=(model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWujb-6yq4p4",
        "outputId": "7015224c-5270-475b-bc00-25999d214279"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "172/172 [==============================] - 2s 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9032081662413416"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test[:10])\n",
        "print(y_pred[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJMTKKNh7-9U",
        "outputId": "612060cf-abc7-48df-aece-1ce12aa4ac98"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 0 1 1 0 1 1 1]\n",
            "[[1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##chay thu\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "corpus1 = []\n",
        "text = input('Enter Title: ')\n",
        "for i in range(0, len(text)):\n",
        "    \n",
        "    review = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "    review = ' '.join(review)\n",
        "    corpus1.append(review)\n",
        "\n",
        "onehot_repr1=[one_hot(words,voc_size)for words in corpus1] \n",
        "embedded_docs1=pad_sequences(onehot_repr1,padding='pre',maxlen=20)\n",
        "test = np.array(embedded_docs1)\n",
        "y_pred=(model.predict(test) > 0.5).astype(\"int32\")\n",
        "if (y_pred[0]==1):\n",
        "  print('Fake New !!!')\n",
        "else:\n",
        "  print('Real New !!!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhj8xledq4_V",
        "outputId": "4ecc4778-252d-4a2d-a9b1-0c6033abc1d7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Title: Jackie Mason: Hollywood Would Love Trump if He Bombed North Korea over Lack of Trans Bathrooms (Exclusive Video) - Breitbart\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "Real New !!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "def runtest(text):\n",
        "  ps = PorterStemmer()\n",
        "  corpus1 = []\n",
        "  for i in range(0, len(text)):\n",
        "     \n",
        "      review = re.sub('[^a-zA-Z]', ' ', text)\n",
        "      review = review.lower()\n",
        "      review = review.split()\n",
        "      \n",
        "      review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "      review = ' '.join(review)\n",
        "      corpus1.append(review)\n",
        "\n",
        "  onehot_repr1=[one_hot(words,voc_size)for words in corpus1] \n",
        "  embedded_docs1=pad_sequences(onehot_repr1,padding='pre',maxlen=20)\n",
        "  test = np.array(embedded_docs1)\n",
        "  y_pred=(model.predict(test) > 0.5).astype(\"int32\")\n",
        "  return y_pred[0]\n"
      ],
      "metadata": {
        "id": "WvQ6r1_Tbe01"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = input('Enter Title: ')\n",
        "x = runtest(text)\n",
        "\n",
        "if (x==1):\n",
        "  print(text + ' is a Fake New !!!')\n",
        "else:\n",
        "  print(text + ' is a Real New !!!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVimpDKJb9Gm",
        "outputId": "5b19e06b-5056-4121-e12a-59151d343c9b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Title: Iranian woman jailed for fictional unpublished story about woman stoned to death for \n",
            "3/3 [==============================] - 0s 7ms/step\n",
            "Iranian woman jailed for fictional unpublished story about woman stoned to death for  is a Fake New !!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/ai/FnPJ3.h5\")"
      ],
      "metadata": {
        "id": "e7UutrLc1_i0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WS70TXPLmXnK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}